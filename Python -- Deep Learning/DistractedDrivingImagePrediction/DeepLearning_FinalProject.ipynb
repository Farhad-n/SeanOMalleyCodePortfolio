{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distracted Driving Prediction\n",
    "## Deep Learning with python, keras & tensorflow\n",
    "### Sean O'Malley\n",
    "\n",
    "The goal of this analysis is to identify the various types of distracted driving scenarios simply using images. We will accomplish this by using deep learning in python with the keras and a tensorflow backend. \n",
    "\n",
    "As a contextual reference, deep learning is a subset of machine learning that allows algorithms to train itself in order to perform tasks like image and speech recognition. Deep learning accomplishes this by revealing immense amounts of data to multi-layered neural networks.\n",
    "\n",
    "This document will walk you through the entire process of: \n",
    "* Ingest a list of images\n",
    "* Transform them into something that can be understood by a computer\n",
    "* Split into test and training groups\n",
    "* Prepare data to fit into a deep learning model\n",
    "\n",
    "\n",
    "* Sequential API deep learning model\n",
    "* Functional API deep learning model\n",
    "* Functional API deep learning model\n",
    "    + with inception module architecture\n",
    "* Functional API deep learning model\n",
    "    + with inception module architecture\n",
    "    + using BatchNormalization to combat overfitting\n",
    "\n",
    "Providing commentary, summary statistics and visualization along the way, we will determine the most successful model to move forward with in identifying distracted driving via images. \n",
    "\n",
    "We will conclude with a summary of the strengths, weaknesses and opportunities for improvement in the models to help fully understand the data, the models and the ultimate application of the analysis.\n",
    "\n",
    "\n",
    "__Package Import__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Packages\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "# Deep Learning Packages\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Concatenate, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import h5py\n",
    "\n",
    "# Image Import & View Packages\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exploratory Data Analysis__\n",
    "\n",
    "Ingest and view summaries of csv's to help us gain an understanding of the data we have. Looking at the data below, you'll see that we have 10 classes of images, living in separate photos. The photos are already categorized in their predefined classes by folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_imgs_list = pd.read_csv('driver_imgs_list.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_imgs_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              img   c0   c1   c2   c3   c4   c5   c6   c7   c8   c9\n",
       "0       img_1.jpg  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
       "1      img_10.jpg  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
       "2     img_100.jpg  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
       "3    img_1000.jpg  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
       "4  img_100000.jpg  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Image Characteristics__\n",
    "\n",
    "We see that the images are jpegs, 640x480 pixels and in full RGB color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG (320, 240) RGB\n"
     ]
    }
   ],
   "source": [
    "print(imagetest.format, imagetest.size, imagetest.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ingest The Test Data__\n",
    "\n",
    "This is the final test data our model will attempt to classify. We do now have a access to the actual classification values of this test data, so to test / train our model we will divide the previously classified data into test and train data then run the model we built against this unknown distracted driver data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79726\n",
      "25000\n",
      "Number of test images: 25000\n",
      "(25000, 64, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "#y = []\n",
    "path = os.path.join('imgs', 'test','*.jpg')\n",
    "img_list = glob.glob(path)\n",
    "print(len(img_list))\n",
    "print(len(img_list[:25000]))\n",
    "\n",
    "for file in img_list[:25000]:\n",
    "    img = Image.open(file).convert('L')\n",
    "    height, width = img.size\n",
    "    # thumbnail is a in-place operation\n",
    "    img = img.resize(( int(height/10), int(width/10) ), Image.ANTIALIAS) #, Image.ANTIALIAS\n",
    "    pix = np.array(img.getdata()).reshape(img.size[0],img.size[1],1)\n",
    "    X_test.append(pix)\n",
    "    #y.append(j)\n",
    "        \n",
    "print(\"Number of test images: %s\" % len(X_test))\n",
    "\n",
    "X_test = np.array(X_test) \n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Manipulate and Transform Image Data__\n",
    "\n",
    "The below outer for loop ingests each image from their respective folders while maintaining the classification of the image.\n",
    "\n",
    "The nested for loop takes each image, converts it to black and white, reduces the image by a magnitued of 10, puts the image pixel values into a numpy array, appending values to the respective X (train) and y (test) lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load folder c0\n",
      "Number of train images: 2489\n",
      "Load folder c1\n",
      "Number of train images: 4756\n",
      "Load folder c2\n",
      "Number of train images: 7073\n",
      "Load folder c3\n",
      "Number of train images: 9419\n",
      "Load folder c4\n",
      "Number of train images: 11745\n",
      "Load folder c5\n",
      "Number of train images: 14057\n",
      "Load folder c6\n",
      "Number of train images: 16382\n",
      "Load folder c7\n",
      "Number of train images: 18384\n",
      "Load folder c8\n",
      "Number of train images: 20295\n",
      "Load folder c9\n",
      "Number of train images: 22424\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for j in range(10):\n",
    "    print('Load folder c{}'.format(j))\n",
    "    path = os.path.join('imgs', 'train', 'c' + str(j), '*.jpg')\n",
    "    img_list = glob.glob(path)\n",
    "    for file in img_list:\n",
    "        img = Image.open(file).convert('L')\n",
    "        height, width = img.size\n",
    "       # thumbnail is a in-place operation\n",
    "        img = img.resize(( int(height/10), int(width/10) ), Image.ANTIALIAS) #, Image.ANTIALIAS\n",
    "        pix = np.array(img.getdata()).reshape(img.size[0],img.size[1],1)\n",
    "        X.append(pix)\n",
    "        y.append(j)\n",
    "        \n",
    "    print(\"Number of train images: %s\" % len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Encode X and y__\n",
    "\n",
    "Because we are attempting to classify the images, we need to change y to categorical data for keras to understand what it is trying to classify. We also need to alter X to be a numpy array because the loop outputs a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22424, 10)\n"
     ]
    }
   ],
   "source": [
    "Y = to_categorical(y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22424, 64, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X) \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test / Train Shuffle and Split__\n",
    "\n",
    "We then take the X and y lists and turn them into float value numpy arrays. After that, we shuffle the order of the data image by index and then split into test and train groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep Shuffle on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9994  4965  5208  2681 15911  5972   547 12219 18670 16198]\n"
     ]
    }
   ],
   "source": [
    "ind = np.array(list(range(22424)))\n",
    "seed = 500\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(ind)\n",
    "print(ind[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply shuffle to test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = X[ind]\n",
    "Ys = Y[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Determine validity of split__\n",
    "\n",
    "Comparing X with Xs we can see that we have properly shuffled our test / train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Ys:(22424, 10)\n",
      "shape of Xs:(22424, 64, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of Ys:\" + str(Ys.shape))\n",
    "print(\"shape of Xs:\" + str(Xs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y looks properly shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.] [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y[0], Ys[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X also looks like things have been shuffled correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35584"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].sum() - Xs[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normalization Process__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "print(Xs.dtype)\n",
    "print(Xs.max()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = (Xs-(Xs.max()/2))/Xs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "-0.142253596592\n",
      "0.5\n",
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "print(Xs.dtype)\n",
    "print(Xs.mean())\n",
    "print(Xs.max())\n",
    "print(Xs.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alter datatype to float to create more disk space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original disk space with float64 is 0.551092224\n",
      "new disk space: float32 is 0.275546112\n"
     ]
    }
   ],
   "source": [
    "print(\"original disk space with \" + str(Xs.dtype) + \" is \" + str(Xs.nbytes/10**9)) \n",
    "Xs = Xs.astype('float32')\n",
    "print(\"new disk space: \"  + str(Xs.dtype) + \" is \" + str(Xs.nbytes/10**9)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Save to hdf5 file type__\n",
    "\n",
    "Due to size and hierarchical data structure, which lets you assign tags/groups or subgroups to your data\n",
    "\n",
    "_Training Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('traindata.hdf5','w') as f:\n",
    "    f.create_dataset('X', data=Xs)\n",
    "    f.create_dataset('Y', data=Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('traindata.hdf5','r') as f:\n",
    "    X_train = f['X'][()] #the [()] means load all data\n",
    "    X_part = f['X'][:10000] #read first 1000 samples\n",
    "    \n",
    "    Y_train = f['Y'][()] #the [()] means load all data\n",
    "    Y_part = f['Y'][:10000] #read first 1000 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Testing Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('testdata.hdf5','w') as f:\n",
    "    f.create_dataset('X', data=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('testdata.hdf5','r') as f:\n",
    "    X_test = f['X'][()] #the [()] means load all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize the results of the data we just brought back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Test\n",
      "(25000, 64, 48, 1)\n",
      "X Train\n",
      "(22424, 64, 48, 1) (10000, 64, 48, 1)\n",
      "Y Train:\n",
      "(22424, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"X Test\")\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"X Train\")\n",
    "print(X_train.shape, X_part.shape)\n",
    "\n",
    "print(\"Y Train:\")\n",
    "print(Y_train.shape, Y_part.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.set_image_dim_ordering( 'tf' )\n",
    "\n",
    "# one hot encode outputs\n",
    "#y_train = to_categorical(y_train)\n",
    "#y_test = to_categorical(y_test)\n",
    "#num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
