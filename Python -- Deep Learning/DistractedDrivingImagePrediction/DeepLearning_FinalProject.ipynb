{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distracted Driving Prediction\n",
    "## Deep Learning with python, keras & tensorflow\n",
    "### Sean O'Malley\n",
    "\n",
    "The goal of this analysis is to identify the various types of distracted driving scenarios simply using images. We will accomplish this by using deep learning in python with the keras and a tensorflow backend. \n",
    "\n",
    "As a contextual reference, deep learning is a subset of machine learning that allows algorithms to train itself in order to perform tasks like image and speech recognition. Deep learning accomplishes this by revealing immense amounts of data to multi-layered neural networks.\n",
    "\n",
    "This document will walk you through the entire process of: \n",
    "* Ingest a list of images\n",
    "* Transform them into something that can be understood by a computer\n",
    "* Split into test and training groups\n",
    "* Prepare data to fit into a deep learning model\n",
    "\n",
    "\n",
    "* Sequential API deep learning model\n",
    "* Functional API deep learning model\n",
    "* Functional API deep learning model\n",
    "    + with inception module architecture\n",
    "* Functional API deep learning model\n",
    "    + with inception module architecture\n",
    "    + using BatchNormalization to combat overfitting\n",
    "\n",
    "Providing commentary, summary statistics and visualization along the way, we will determine the most successful model to move forward with in identifying distracted driving via images. \n",
    "\n",
    "We will conclude with a summary of the strengths, weaknesses and opportunities for improvement in the models to help fully understand the data, the models and the ultimate application of the analysis.\n",
    "\n",
    "\n",
    "__Package Import__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Packages\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "# Deep Learning Packages\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Input, Concatenate, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical, np_utils\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import h5py\n",
    "\n",
    "# Image Import & View Packages\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exploratory Data Analysis__\n",
    "\n",
    "Ingest and view summaries of csv's to help us gain an understanding of the data we have. Looking at the data below, you'll see that we have 10 classes of images, living in separate photos. The photos are already categorized in their predefined classes by folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_imgs_list = pd.read_csv('driver_imgs_list.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_imgs_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              img   c0   c1   c2   c3   c4   c5   c6   c7   c8   c9\n",
       "0       img_1.jpg  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
       "1      img_10.jpg  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
       "2     img_100.jpg  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
       "3    img_1000.jpg  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1\n",
       "4  img_100000.jpg  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Image Characteristics__\n",
    "\n",
    "We see that the images are jpegs, 640x480 pixels and in full RGB color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG (320, 240) RGB\n"
     ]
    }
   ],
   "source": [
    "print(imagetest.format, imagetest.size, imagetest.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ingest The Test Data__\n",
    "\n",
    "This is the final test data our model will attempt to classify. We do now have a access to the actual classification values of this test data, so to test / train our model we will divide the previously classified data into test and train data then run the model we built against this unknown distracted driver data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79726\n",
      "25000\n",
      "Number of test images: 25000\n",
      "(25000, 64, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "#y = []\n",
    "path = os.path.join('imgs', 'test','*.jpg')\n",
    "img_list = glob.glob(path)\n",
    "print(len(img_list))\n",
    "print(len(img_list[:25000]))\n",
    "\n",
    "for file in img_list[:25000]:\n",
    "    img = Image.open(file).convert('L')\n",
    "    height, width = img.size\n",
    "    # thumbnail is a in-place operation\n",
    "    img = img.resize(( int(height/10), int(width/10) ), Image.ANTIALIAS) #, Image.ANTIALIAS\n",
    "    pix = np.array(img.getdata()).reshape(img.size[0],img.size[1],1)\n",
    "    X_test.append(pix)\n",
    "    #y.append(j)\n",
    "        \n",
    "print(\"Number of test images: %s\" % len(X_test))\n",
    "\n",
    "X_test = np.array(X_test) \n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Manipulate and Transform Image Data__\n",
    "\n",
    "The below outer for loop ingests each image from their respective folders while maintaining the classification of the image.\n",
    "\n",
    "The nested for loop takes each image, converts it to black and white, reduces the image by a magnitued of 10, puts the image pixel values into a numpy array, appending values to the respective X (train) and y (test) lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load folder c0\n",
      "Number of train images: 2489\n",
      "Load folder c1\n",
      "Number of train images: 4756\n",
      "Load folder c2\n",
      "Number of train images: 7073\n",
      "Load folder c3\n",
      "Number of train images: 9419\n",
      "Load folder c4\n",
      "Number of train images: 11745\n",
      "Load folder c5\n",
      "Number of train images: 14057\n",
      "Load folder c6\n",
      "Number of train images: 16382\n",
      "Load folder c7\n",
      "Number of train images: 18384\n",
      "Load folder c8\n",
      "Number of train images: 20295\n",
      "Load folder c9\n",
      "Number of train images: 22424\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for j in range(10):\n",
    "    print('Load folder c{}'.format(j))\n",
    "    path = os.path.join('imgs', 'train', 'c' + str(j), '*.jpg')\n",
    "    img_list = glob.glob(path)\n",
    "    for file in img_list:\n",
    "        img = Image.open(file).convert('L')\n",
    "        height, width = img.size\n",
    "       # thumbnail is a in-place operation\n",
    "        img = img.resize(( int(height/10), int(width/10) ), Image.ANTIALIAS) #, Image.ANTIALIAS\n",
    "        pix = np.array(img.getdata()).reshape(img.size[0],img.size[1],1)\n",
    "        X.append(pix)\n",
    "        y.append(j)\n",
    "        \n",
    "    print(\"Number of train images: %s\" % len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Encode X and y__\n",
    "\n",
    "Because we are attempting to classify the images, we need to change y to categorical data for keras to understand what it is trying to classify. We also need to alter X to be a numpy array because the loop outputs a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22424, 10)\n"
     ]
    }
   ],
   "source": [
    "Y = to_categorical(y)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22424, 64, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X) \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test / Train Shuffle and Split__\n",
    "\n",
    "We then take the X and y lists and turn them into float value numpy arrays. After that, we shuffle the order of the data image by index and then split into test and train groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep Shuffle on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9994  4965  5208  2681 15911  5972   547 12219 18670 16198]\n"
     ]
    }
   ],
   "source": [
    "ind = np.array(list(range(22424)))\n",
    "seed = 500\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(ind)\n",
    "print(ind[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply shuffle to test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = X[ind]\n",
    "Ys = Y[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Determine validity of split__\n",
    "\n",
    "Comparing X with Xs we can see that we have properly shuffled our test / train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Ys:(22424, 10)\n",
      "shape of Xs:(22424, 64, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of Ys:\" + str(Ys.shape))\n",
    "print(\"shape of Xs:\" + str(Xs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y looks properly shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.] [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y[0], Ys[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X also looks like things have been shuffled correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35584"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].sum() - Xs[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normalization Process__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "print(Xs.dtype)\n",
    "print(Xs.max()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = (Xs-(Xs.max()/2))/Xs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "-0.142253596592\n",
      "0.5\n",
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "print(Xs.dtype)\n",
    "print(Xs.mean())\n",
    "print(Xs.max())\n",
    "print(Xs.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alter datatype to float to create more disk space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original disk space with float64 is 0.551092224\n",
      "new disk space: float32 is 0.275546112\n"
     ]
    }
   ],
   "source": [
    "print(\"original disk space with \" + str(Xs.dtype) + \" is \" + str(Xs.nbytes/10**9)) \n",
    "Xs = Xs.astype('float32')\n",
    "print(\"new disk space: \"  + str(Xs.dtype) + \" is \" + str(Xs.nbytes/10**9)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Save to hdf5 file type__\n",
    "\n",
    "Due to size and hierarchical data structure, which lets you assign tags/groups or subgroups to your data. I will also re-ingest the data in a way that automatically creates the test and train groups for our model to learn on. \n",
    "\n",
    "_Training Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('traindata.hdf5','w') as f:\n",
    "    f.create_dataset('X', data=Xs)\n",
    "    f.create_dataset('Y', data=Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('traindata.hdf5','r') as f:\n",
    "    X_train = f['X'][7001:] #the [()] means load all data\n",
    "    X_test = f['X'][:7000] #read first 1000 samples\n",
    "    \n",
    "    Y_train = f['Y'][7001:] #the [()] means load all data\n",
    "    Y_test = f['Y'][:7000] #read first 1000 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Final Testing Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('testdata.hdf5','w') as f:\n",
    "    f.create_dataset('X', data=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('testdata.hdf5','r') as f:\n",
    "    X_Final_Test = f['X'][()] #the [()] means load all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Visualize Shape before modeling__\n",
    "\n",
    "We want to see the structure of the data we are using to teach our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Test\n",
      "(7000, 64, 48, 1)\n",
      "X Train\n",
      "(15423, 64, 48, 1)\n",
      "Y Test:\n",
      "(7000, 10)\n",
      "Y Train:\n",
      "(15423, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"X Test\")\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"X Train\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"Y Test:\")\n",
    "print(Y_test.shape)\n",
    "\n",
    "print(\"Y Train:\")\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic Sequential Model:__ _Build_\n",
    "\n",
    "The <a href=\"https://keras.io/models/sequential/\">Sequential API</a> allows you to create models layer by layer after initiating the _Sequential()_ function in a model. The operations are limited in that Sequential does not allow you to create models that share layers or have multiple inputs or outputs. However this simple model can prove incredibly effective, permitting you to summarize, fit, evaluate and make predictions.\n",
    "\n",
    "We first want to prep the inputs to the model. Pulling out the number of classes and ensuring that y is categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "num_classes = Y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets build the most basic sequential model and see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model as Function\n",
    "def simple_sequential_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15423 samples, validate on 7000 samples\n",
      "Epoch 1/20\n",
      " - 32s - loss: 2.1491 - acc: 0.4655 - val_loss: 1.1858 - val_acc: 0.6167\n",
      "Epoch 2/20\n",
      " - 30s - loss: 0.6972 - acc: 0.8271 - val_loss: 0.4695 - val_acc: 0.9006\n",
      "Epoch 3/20\n",
      " - 31s - loss: 0.3253 - acc: 0.9348 - val_loss: 0.2924 - val_acc: 0.9284\n",
      "Epoch 4/20\n",
      " - 32s - loss: 0.1872 - acc: 0.9651 - val_loss: 0.1970 - val_acc: 0.9539\n",
      "Epoch 5/20\n",
      " - 32s - loss: 0.1202 - acc: 0.9790 - val_loss: 0.1764 - val_acc: 0.9541\n",
      "Epoch 6/20\n",
      " - 30s - loss: 0.0934 - acc: 0.9824 - val_loss: 0.1207 - val_acc: 0.9740\n",
      "Epoch 7/20\n",
      " - 28s - loss: 0.0717 - acc: 0.9864 - val_loss: 0.1052 - val_acc: 0.9739\n",
      "Epoch 8/20\n",
      " - 27s - loss: 0.0515 - acc: 0.9907 - val_loss: 0.0855 - val_acc: 0.9781\n",
      "Epoch 9/20\n",
      " - 28s - loss: 0.0445 - acc: 0.9916 - val_loss: 0.0768 - val_acc: 0.9813\n",
      "Epoch 10/20\n",
      " - 27s - loss: 0.0353 - acc: 0.9940 - val_loss: 0.0604 - val_acc: 0.9854\n",
      "Epoch 11/20\n",
      " - 27s - loss: 0.0234 - acc: 0.9970 - val_loss: 0.0649 - val_acc: 0.9817\n",
      "Epoch 12/20\n",
      " - 27s - loss: 0.0189 - acc: 0.9977 - val_loss: 0.0485 - val_acc: 0.9889\n",
      "Epoch 13/20\n",
      " - 28s - loss: 0.0139 - acc: 0.9988 - val_loss: 0.0575 - val_acc: 0.9850\n",
      "Epoch 14/20\n",
      " - 28s - loss: 0.0139 - acc: 0.9989 - val_loss: 0.0410 - val_acc: 0.9900\n",
      "Epoch 15/20\n",
      " - 28s - loss: 0.0105 - acc: 0.9993 - val_loss: 0.0379 - val_acc: 0.9897\n",
      "Epoch 16/20\n",
      " - 28s - loss: 0.0081 - acc: 0.9997 - val_loss: 0.0429 - val_acc: 0.9896\n",
      "Epoch 17/20\n",
      " - 28s - loss: 0.0071 - acc: 0.9997 - val_loss: 0.0383 - val_acc: 0.9901\n",
      "Epoch 18/20\n",
      " - 27s - loss: 0.0067 - acc: 0.9997 - val_loss: 0.0349 - val_acc: 0.9909\n",
      "Epoch 19/20\n",
      " - 27s - loss: 0.0048 - acc: 0.9999 - val_loss: 0.0350 - val_acc: 0.9907\n",
      "Epoch 20/20\n",
      " - 27s - loss: 0.0042 - acc: 0.9999 - val_loss: 0.0341 - val_acc: 0.9911\n",
      "Baseline Error: 0.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x162223978>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Model\n",
    "model = simple_sequential_model()\n",
    "\n",
    "# Fit Model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=20, batch_size=200, verbose=2)\n",
    "\n",
    "# Evaluate Model\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "# Visualize Model\n",
    "plt.plot(history.history['acc'],'b') #train acc\n",
    "plt.plot(history.history['val_acc'],'g') #val acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic Sequential Model:__  _Evaluate_\n",
    "\n",
    "This appears to be an extremely accurate model, however this could very well be me screwing something up, because its an incredibly simple model and in my mind should not be able to predict this well.\n",
    "\n",
    "__Save Model__\n",
    "\n",
    "We want so save this specific model off as a json, and weights to hdf5 for reusability purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"simple_sequential_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"simple_sequential_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Read in Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('simple_sequential_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"simple_sequential_model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic Sequential Model:__ _Predict Final Test Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "#loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "#print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
